{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "from PIL import Image, ImageDraw\n",
    "from torchvision import transforms\n",
    "from pathlib import Path\n",
    "from nets.ROAR import ROAR\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = Path('./data/test_set/labeled_data_test.csv')\n",
    "image_folder = Path('./data/test_set/images_test/')\n",
    "network_weights = Path('./experiments/roar/model.pth')\n",
    "pretrained_image_weights = Path('./weights/VisionNavNet_state_hd.pth.tar')\n",
    "sequence = 1\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = ROAR(device, True, pretrained_image_weights, 10)\n",
    "network.to(device)\n",
    "network.load_state_dict(torch.load(network_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = pd.read_csv(csv_file)\n",
    "csv = csv[csv['sequence'] == sequence].reset_index(drop=True)\n",
    "print(\"Number of samples: {}\".format(csv.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions for reading and visualizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ego_trajectory(pred_traj, f, cam_height, image_width, image_height):\n",
    "    predXs = pred_traj[:,0]\n",
    "    predYs = pred_traj[:,1]\n",
    "    xs = f * predYs / predXs\n",
    "    ys = f * cam_height / predXs\n",
    "    xs = -xs + image_width / 2\n",
    "    ys = -ys + image_height / 2\n",
    "    ego_traj = [(x,y) for x,y in zip (xs, ys)]\n",
    "    return ego_traj\n",
    "\n",
    "\n",
    "def read_datapoint(datapoint):\n",
    "    # Constants\n",
    "    lidar_clip = 1.85\n",
    "    f = 460\n",
    "    image_width, image_height = 320, 240\n",
    "    cam_height = -0.23\n",
    "\n",
    "    # Helper lambdas\n",
    "    map_to_float = lambda x: np.array(list(map(float, x)))\n",
    "    map_to_int = lambda x: np.array(list(map(int, x)))\n",
    "    \n",
    "    # Read image\n",
    "    image_name = image_folder / datapoint['image_name']\n",
    "    image = io.imread(image_name)\n",
    "    image = Image.fromarray(image)\n",
    "    \n",
    "    # Create data for traj image\n",
    "    predX = datapoint['pred_traj_x'][1:-1].split(',')\n",
    "    predY = datapoint['pred_traj_y'][1:-1].split(',')\n",
    "    predX = abs(map_to_float(predX))\n",
    "    predY = map_to_float(predY)\n",
    "    pred_traj = torch.tensor(np.stack([predX, predY])).to(torch.float32).permute(1,0)\n",
    "\n",
    "    # Get LiDAR data\n",
    "    lidar_scan = datapoint['lidar_scan'][1:-1].split(',')\n",
    "    lidar_scan = map_to_float(lidar_scan)\n",
    "    # Clip LiDAR\n",
    "    lidar_scan_clipped = np.clip(lidar_scan, a_min=0, a_max=lidar_clip) / lidar_clip\n",
    "    lidar_scan_clipped = torch.as_tensor(lidar_scan_clipped, dtype=torch.float32)\n",
    "\n",
    "    # Get label\n",
    "    label = datapoint['label'][1:-1].split(',')\n",
    "    label = map_to_int(label)\n",
    "    label = torch.as_tensor(label, dtype=torch.float32)\n",
    "    \n",
    "    # Get occlusion labels and sequence number\n",
    "    image_occluded = int(datapoint['image_occluded'])\n",
    "    lidar_occluded = int(datapoint['lidar_occluded'])\n",
    "    sequence_number = int(datapoint['sequence'])\n",
    "\n",
    "    # Process the data\n",
    "    image_tx = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "    image_tensor = image_tx(image)\n",
    "\n",
    "    # Create trajectory data\n",
    "    ego_traj = get_ego_trajectory(pred_traj, f, cam_height, image_width, image_height)\n",
    "    traj_image = Image.new(mode=\"L\", size=(image_width, image_height))\n",
    "    traj_draw = ImageDraw.Draw(traj_image)\n",
    "    traj_draw.line(ego_traj, fill=\"white\", width=6, joint=\"curve\")\n",
    "    traj_image = traj_image.crop((0, 112, 320, 240))\n",
    "    traj_image = transforms.ToTensor()(traj_image)\n",
    "    \n",
    "    return {\n",
    "        'image': image,\n",
    "        'image_tensor': image_tensor,\n",
    "        'lidar_scan': lidar_scan,\n",
    "        'lidar_scan_clipped': lidar_scan_clipped,\n",
    "        'traj_image_tensor': traj_image,\n",
    "        'image_occluded': image_occluded,\n",
    "        'lidar_occluded': lidar_occluded,\n",
    "        'label': label\n",
    "    }\n",
    "\n",
    "def predict(network, sequence, reset_state_each_frame=False):\n",
    "    # Predict\n",
    "    predictions = []\n",
    "    network.eval()\n",
    "    with torch.no_grad():\n",
    "        state = None\n",
    "        for entry in tqdm.tqdm(sequence):\n",
    "            p = network(entry['image_tensor'].to(device).unsqueeze(0).unsqueeze(0),\n",
    "                        entry['traj_image_tensor'].to(device).unsqueeze(0).unsqueeze(0),\n",
    "                        entry['lidar_scan_clipped'].to(device).unsqueeze(0).unsqueeze(0),\n",
    "                        initial_state=state)\n",
    "            if reset_state_each_frame:\n",
    "                state = None\n",
    "            else:\n",
    "                state = p['state']\n",
    "            pred_scores = list(p['pred_inv_score'].flatten(0,1).cpu().numpy()[0])\n",
    "            pred_images = p['pred_img_score'].flatten(0,1).cpu().numpy()[0][0]\n",
    "            pred_lidars = p['pred_lidar_score'].flatten(0,1).cpu().numpy()[0][0]\n",
    "            predictions.append({\n",
    "                'predicted_label': pred_scores,\n",
    "                'predicted_lidar': pred_lidars,\n",
    "                'predicted_camera': pred_images\n",
    "            })\n",
    "    return predictions\n",
    "\n",
    "def visualize(frame_data, frame_predictions, title=\"\", show_gts=False):\n",
    "    plt.rcParams.update({\n",
    "        'font.size': 14\n",
    "    })\n",
    "    plt.rcParams['font.family'] = 'serif'\n",
    "    plt.rcParams['font.serif'] = ['Times New Roman'] + plt.rcParams['font.serif']\n",
    "    fig = plt.figure(figsize=(14,4))\n",
    "    if title is not None:\n",
    "        fig.suptitle(title)\n",
    "    axs = fig.subplots(1,3, gridspec_kw={'width_ratios': [2, 1, 1]})\n",
    "\n",
    "    # Get predicted trajectory\n",
    "    traj = torch.cat([torch.zeros(1,240-128,320), frame_data['traj_image_tensor']], dim=1)[0]\n",
    "    render = transforms.ToPILImage()(transforms.ToTensor()(frame_data['image']) * (1.0 - traj) + torch.stack([torch.zeros_like(traj), torch.zeros_like(traj), traj]))\n",
    "    # Get lidar\n",
    "    theta = np.linspace(-0.25*np.pi, 1.25*np.pi, 1081)\n",
    "    lidar_xs = frame_data['lidar_scan'] * np.cos(theta)\n",
    "    lidar_ys = frame_data['lidar_scan'] * np.sin(theta)\n",
    "\n",
    "    axs[0].imshow(render)\n",
    "    axs[0].axis('off')\n",
    "\n",
    "    axs[1].plot(lidar_xs, lidar_ys, ls='None', color='white', marker='.', markersize=5)\n",
    "    axs[1].plot(0, 0, color='tab:blue', marker='^', markersize=15)\n",
    "    axs[1].axis([-1, 1, -0.75, 2.0])\n",
    "    axs[1].set_xticks([])\n",
    "    axs[1].set_yticks([])\n",
    "    axs[1].set_facecolor('black')\n",
    "\n",
    "    axs[2].plot(range(1,11), frame_predictions['predicted_label'])\n",
    "    axs[2].set_xlabel('Timesteps ahead')\n",
    "    axs[2].set_ylabel('Probability of Failure')\n",
    "    axs[2].set_ylim(-0.1,1.1)\n",
    "    axs[2].set_facecolor('white')\n",
    "    axs[2].plot(range(1,11), [0.5]*10, color='red')\n",
    "    if show_gts:\n",
    "        axs[2].scatter(range(1,11), frame_data['label'], color='orange')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = [read_datapoint(csv.iloc[i]) for i in range(csv.shape[0])]\n",
    "predictions = predict(network=network, sequence=sequence, reset_state_each_frame=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_to_show = list(range(0,len(sequence)))\n",
    "\n",
    "for idx in frames_to_show:\n",
    "    visualize(sequence[idx], predictions[idx], show_gts=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fieldAD",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
